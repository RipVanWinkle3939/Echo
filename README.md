# Echo
在AR中探索肢体交互、图像视觉和声音合成的关系

***“Echo”（暂用名）是由中国美术学院创新设计学院媒介与交互研究所学生进行并在Github同步更新进度的数字媒体艺术项目***

###### ——————2023/12/8——————
我们试图

 1. 探究单人、双人以至多人间，在AR语境下的交互形式，并将所有的点子记录下来。这个被记录的点子将详细记录该交互动作的过程以及点子诞生时随之而生的思考。并且这个点子将被存储为一个视频文件、肢体动作追踪的osc信号数据包以及对其进行描述的文本文件。
 2. 对被记录的点子进行详细的语义解读，再进行初步的视觉设计——该点子中所记录的动作在AR中可以对应什么样的视觉，动作数据的变化对视觉又会有什么样的影响。
 3. 对被记录的点子进行声音设计——该点子中所记录的动作可以对应到什么样的声音，动作数据的变化对声音又会有什么样的影响。

我将在此对这样的行为进行记录，囿于过程可读性，暂且仅将过程“1”以及其中产出的文件进行记录。
| “点子”代号 | 日期 | 视频 | osc数据包 | 备注 |
|--|--|--|--|--|
|  |  |  |  |  |

